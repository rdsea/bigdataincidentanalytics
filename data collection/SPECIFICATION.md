# Data Collection

The collection of various types of monitoring information (such as metrics, logs, traces) from pipeline components can be split up into three main layers whereby these layers intertwine:

* Infrastructure:
  * Provider's Server: this is the lowest level of abstraction. This can be a physical or virtual (even dynamic) server of the stakeholder who provides a certain Big Data functionality. The amount of available information about this is generally close to nothing unless it is self-hosted and controlled. 
  * Application Platform's Server: this is an optional intermediary abstraction of the execution environment where the provided functionality's application is executed. It is called _application platform_ to make the clear distinction between the provided service's application (e.g. Nifi) and the consumer's own business-specific application logic (e.g. Flows in Nifi). This server may be virtual, such as a Docker container. The amount of available information depends on to which degree the consumer has control over the platform's execution environment, hosting and/or deployment. Obviously it is possible that the infrastructure layer consists of either only one of these or of multiple virtualization environments.
* Application Platform: this layer is specific to provided functionality's application code. This strictly excludes the consumer's custom application code. Again, depending on the degree of control/ownership, it is possible to gather log files generated by the platform's application.
* Application: this is the top layer representing consumer-specific functions, executable artifacts, blocks of code over which the consumer has complete control. The most important property of this layer is that it is instrumentable by the consumer themselves.

It is important to note that the above listing describes the layers from bottom to top. Generally it can be observed that the higher the examined layer is the more monitoring information can be gathered. However this assumption is not always true, since the control over layers can be random.

#### Infrastructure

| Information/Metric                                           | Source | Tool |
| ------------------------------------------------------------ | ------ | ---- |
| Percent of time over the past sample period during which the accelerator was actively processing | cAdvisor | Prometheus |
| Percent of time over the past sample period during which the accelerator was actively processing | cAdvisor | Prometheus |
| Total accelerator memory                                     | cAdvisor | Prometheus |
| Total accelerator memory allocated                           | cAdvisor | Prometheus |
| Number of elapsed enforcement period intervals               | cAdvisor | Prometheus |
| Number of throttled period intervals                         | cAdvisor | Prometheus |
| Total time duration the container has been throttled         | cAdvisor | Prometheus |
| Value of container cpu load average over the last 10 seconds | cAdvisor | Prometheus |
| Number of times processes of the cgroup have run on the cpu  | cAdvisor | Prometheus |
| Time duration the processes of the container have run on the CPU | cAdvisor | Prometheus |
| Time duration processes of the container have been waiting on a runqueue | cAdvisor | Prometheus |
| Cumulative system cpu time consumed                          | cAdvisor | Prometheus |
| Cumulative cpu time consumed                                 | cAdvisor | Prometheus |
| Cumulative user cpu time consumed                            | cAdvisor | Prometheus |
| Number of open file descriptors for the container            | cAdvisor | Prometheus |
| Number of available Inodes                                   | cAdvisor | Prometheus |
| Total number of Inodes                                       | cAdvisor | Prometheus |
| Number of I/Os currently in progress                         | cAdvisor | Prometheus |
| Cumulative count of seconds spent doing I/Os                 | cAdvisor | Prometheus |
| Cumulative weighted I/O time                                 | cAdvisor | Prometheus |
| Number of bytes that can be consumed by the container on this filesystem | cAdvisor | Prometheus |
| Cumulative count of bytes read                               | cAdvisor | Prometheus |
| Cumulative count of reads completed                          | cAdvisor | Prometheus |
| Cumulative count of seconds spent reading                    | cAdvisor | Prometheus |
| Cumulative count of reads merged                             | cAdvisor | Prometheus |
| Cumulative count of sector reads completed                   | cAdvisor | Prometheus |
| Cumulative count of sector writes completed                  | cAdvisor | Prometheus |
| Number of bytes that are consumed by the container on this filesystem | cAdvisor | Prometheus |
| Cumulative count of seconds spent writing                    | cAdvisor | Prometheus |
| Cumulative count of bytes written                            | cAdvisor | Prometheus |
| Cumulative count of writes merged                            | cAdvisor | Prometheus |
| Cumulative count of writes completed                         | cAdvisor | Prometheus |
| Last time a container was seen by the exporter               | cAdvisor | Prometheus |
| Total page cache memory                                      | cAdvisor | Prometheus |
| Number of memory usage hits limits                           | cAdvisor | Prometheus |
| Cumulative count of memory allocation failures               | cAdvisor | Prometheus |
| Maximum memory usage recorded                                | cAdvisor | Prometheus |
| Size of RSS                                                  | cAdvisor | Prometheus |
| Container swap usage                                         | cAdvisor | Prometheus |
| Size of memory mapped files                                  | cAdvisor | Prometheus |
| Current memory usage, including all memory regardless of when it was accessed | cAdvisor | Prometheus |
| Current working set                                          | cAdvisor | Prometheus |
| Cumulative count of bytes received                           | cAdvisor | Prometheus |
| Cumulative count of packets dropped while receiving          | cAdvisor | Prometheus |
| Cumulative count of packets received                         | cAdvisor | Prometheus |
| Cumulative count of errors encountered while receiving       | cAdvisor | Prometheus |
| Cumulative count of bytes transmitted                        | cAdvisor | Prometheus |
| Cumulative count of packets transmitted                      | cAdvisor | Prometheus |
| Cumulative count of packets dropped while transmitting       | cAdvisor | Prometheus |
| Cumulative count of errors encountered while transmitting    | cAdvisor | Prometheus |
| tcp connection usage statistic for container                 | cAdvisor | Prometheus |
| tcp6 connection usage statistic for container                | cAdvisor | Prometheus |
| udp connection usage statistic for container                 | cAdvisor | Prometheus |
| udp6 connection usage statistic for container                | cAdvisor | Prometheus |
| Number of processes running inside the container             | cAdvisor | Prometheus |
| CPU period of the container                                  | cAdvisor | Prometheus |
| CPU quota of the container                                   | cAdvisor | Prometheus |
| CPU share of the container                                   | cAdvisor | Prometheus |
| Memory limit for the container                               | cAdvisor | Prometheus |
| Memory swap limit for the container                          | cAdvisor | Prometheus |
| Memory reservation limit for the container                   | cAdvisor | Prometheus |
| Start time of the container since unix epoch                 | cAdvisor | Prometheus |
| Number of tasks in given state (`sleeping`, `running`, `stopped`, `uninterruptible`, or `ioawaiting`) | cAdvisor | Prometheus |

#### Platform

| Information/Metric                                           | Source                                                       | Tool                            |
| ------------------------------------------------------------ | ------------------------------------------------------------ | ------------------------------- |
| raw application platform logs structured via custom parser   | docker logs with Fluentd as logging driver                   | Fluentd                         |
| raw application platform logs structured via side-car FluentBit and sent to central Fluentd | tailing log files, parsing and forwarding them to Fluentd    | FluentBit + Fluentd             |
| JVM application logs via Fluentd appender for Log4J/Logback  | already built-in application logs which get processed by an additional log appender | Log4J/Logback + FluencyAppender |
| accessible application platform logs via custom pluggable code snippets (common for NodeJs apps) | platform induced logs forwarded to central Fluentd instance  | Fluentd                         |

All structured logs arriving in Fluentd which contain "platform" or "docker" in their tag receive the property `"software": "PLATFORM"` and will be handled as platform-level logs.

#### Application

| Information/Metric                                           | Source                                                       | Tool                                                |
| ------------------------------------------------------------ | ------------------------------------------------------------ | --------------------------------------------------- |
| data record including provenance at an execution point of interest: entry (receiving), processing (altering), exit (forwarding, storage) | custom instrumentation according to guidelines               | Fluentd shipper library or simple HTTP json sending |
| analytics information e.g. `assetState`, `function`,`incident`, `effect` | stakeholder defines record decoration for certain tag patterns or applies instrumentation | Fluentd configuration                               |
| optional key-value pairs describing the logged event         | custom instrumentation                                       | Fluentd shipper library or simple HTTP json sending |

All structured logs arriving in Fluentd which contain "app" in their tag receive the property `"software": "APPLICATION"` and will be handled as application-level logs.

The provenance of a generated/received/processed/stored/forwarded arbitrary data should be named `prov` and should contain at least the following properties/information:

- `id`: id of the entity this provenance information belongs to; should describe the component or entity unambiguously
- `type`: description of the data in one word
- `wasDerivedFrom`: the ID of the entity this provenance information has been derived from. It is also allowed to concatenate multiple IDs of entities in case the derivation included multiple entities. See W3C [documentation](https://www.w3.org/TR/prov-dm/#dfn-wasderivedfrom) for more details.
- `wasGeneratedBy`: unique name of the activity that generated a new entity for which this provenance information holds. See W3C [documentation](https://www.w3.org/TR/2013/REC-prov-o-20130430/#wasGeneratedBy) for more details.

It is encouraged to use nano-second precision for timestamps if applicable.

## Topology

For a better correlation of monitoring information and events, a formal description of the pipeline orchestration is required. The [TOSCA](https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=tosca) specification provides an abstract and extensible rule-set in YAML format which allows for different levels of granularity. The most important aspect of the topology is to indicate the known participating components (even if they are not controlled) and how data moves between them. To this end we introduce two new relationship types which are derived from the`tosca.relationships.ConnectsTo` relationship:

- `analytics_data_moves_to`: describes a relationship between two nodes A and B, where it is known that data will always move from A to B. Corresponding scenarios include the asynchronous broadcast messaging and forwarding of data records.
- `analytics_reads_data_from`: describes a relationship between two nodes A and B, where it is known that A will eventually read data from B. In contrast to the previous relationship, here data is not _flowing_ from source to target in a stream-like manner; it is rather queried such as a file access. 

The more information the operator/orchestrator provides about the nodes and relationships, the better the correlation can be. For example if a certain pipeline component is under total control, it is encouraged to also indicate if the platform/middleware is deployed in a Docker container which again is executed on a certain virtual or physical server (can be expressed through the `tosca.relationships.HostedOn` relationship).