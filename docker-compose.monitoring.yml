version: '3.4'

services:

  ##### ELASTICSEARCH FOR STORING LOGS, INCIDENT REPORTS #####
  elasticsearch:
    build:
      context: pipeline/elk/elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: elasticsearch
    volumes:
      - ./pipeline/elk/elasticsearch/data:/usr/share/elasticsearch/data
      - ./pipeline/elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - $ETC_LOCALTIME:/etc/localtime:ro
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - iot-big-data
      - pipeline

  ##### KIBANA FOR VISUALIZATION, DISCOVERY #####
  kibana:
    build:
      context: pipeline/elk/kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: kibana
    volumes:
      - ./pipeline/elk/kibana/config/:/usr/share/kibana/config:ro
      - $ETC_LOCALTIME:/etc/localtime:ro
    ports:
      - 5601:5601
    networks:
      - iot-big-data
    depends_on:
      - elasticsearch


  ##### FLUENTD FOR CENTRALIZING LOGS AND SIGNALS #####
  fluentd:
    build: logging/fluentd
    #image: fluentd:gcp_onpremise # use this image if you want to forward logs into Google Stackdriver
    container_name: fluentd
    volumes:
      #- ./logging/fluentd/gcp/onpremise:/fluentd/etc  # Mount this config for Stackdriver ingestion
      - ./logging/fluentd/conf:/fluentd/etc # Mount this config for local use
      - ./logging/fluentd/logs:/fluentd/log/bigdataincidentanalytics
      - ./logging/fluentd/logs/pipeline:/fluentd/log/bigdataincidentanalytics/pipeline
      # Mount the GCP credentials when ingesting to Stackdriver
      #- ./application_default_credentials.json:/etc/google/auth/application_default_credentials.json
      #- $ETC_LOCALTIME:/etc/localtime:ro
    #environment: # Set this environment variable when ingesting to Stackdriver
      #- APPLICATION_DEFAULT_CREDS="/etc/google/auth/application_default_credentials.json"
    networks:
      - iot-big-data
    ports:
      - 24224:24224
      - 24224:24224/udp
      - 9880:9880

  ##### NEO4J GRAPH DATABASE AS KNOWLEDGE BASE FOR INCIDENT REASONING #####
  neo4j:
    image: neo4j:3.5.14
    container_name: neo4j
    environment:
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,algo.*
      - NEO4J_AUTH=neo4j/test
    volumes:
      - ./reasoning/neo4j/import:/var/lib/neo4j/import
      - ./reasoning/neo4j/data:/data
      - ./reasoning/neo4j/neo4j-graph-algorithms-3.5.14.0-standalone.jar:/var/lib/neo4j/plugins/neo4j-graph-algorithms-3.5.14.0-standalone.jar
      - ./reasoning/neo4j/apoc-3.5.0.7-all.jar:/var/lib/neo4j/plugins/apoc-3.5.0.7-all.jar
    networks:
      - iot-big-data
    ports:
      - 7474:7474
      - 7687:7687

  ##### ZOOKEEPER FOR RUNNING KAFKA CLUSTER #####
  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    networks:
      - iot-big-data
      - pipeline
    ports:
      - 2181:2181

  ##### KAFKA FOR CENTRALIZED, RELIABLE, EXACTLY-ONCE-STREAMING OF SIGNALS #####
  kafka:
    image: wurstmeister/kafka:2.12-2.3.0
    container_name: kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_CREATE_TOPICS: "signals:3:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:29092,OUTSIDE://192.168.0.95:9092
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 3
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - iot-big-data
      - pipeline
    ports:
      - 9092:9092

  ##### BRIDGE BETWEEN PROMETHEUS ALERTS AND THE KAFKA CLUSTER #####
  ingestion-service:
    image: ingestion-service:latest
    container_name: ingestion-service
    expose:
      - 3000
    ports:
      - 3000:3000
    environment:
      KAFKA_BROKERS: "kafka:29092"  # separate multiple brokers by a comma e.g "kafka1:29092,kafka2:29092"
      KAFKA_TOPIC: signals
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: test
    networks:
      - iot-big-data

  ##### LONG-TERM STORAGE OF SIGNALS FOR DATA ANALYSIS #####
  cassandra:
    image: cassandra:3.0
    container_name: cassandra
    ports:
      - 9042:9042
    expose:
      - 9160
    environment:
      JVM_OPTS: "-Xmx256m -Xms256m"
      MAX_HEAP_SIZE: 256M
      HEAP_NEWSIZE: 256M
    volumes:
      - ./reasoning/cassandra/data:/var/lib/cassandra
    networks:
      - iot-big-data

  ##### APACHE SPARK MASTER FOR RUNNING THE FREQUENT PATTERN MINING TASK #####
  analysis-spark-master:
    image: pattern-analysis-spark:latest
    container_name: analysis-spark-master
    ports:
      - 8084:8080
    expose:
      - 7077
    volumes:
      - $ETC_LOCALTIME:/etc/localtime:ro
    networks:
      - iot-big-data

  ##### APACHE SPARK WORKER FOR RUNNING THE FREQUENT PATTERN MINING TASK #####
  analysis-spark-worker:
    image: pattern-analysis-spark:latest
    ports:
      - 8081
    environment:
      SPARK_MASTER: spark://analysis-spark-master:7077
    volumes:
      - $ETC_LOCALTIME:/etc/localtime:ro
    command: /bin/bash /worker.sh
    networks:
      - iot-big-data

  ##### SUBMIT TASK FOR RUNNING THE FREQUENT PATTERN MINING TASK #####
  spark-submit:
    image: pattern-analysis-spark:latest
    container_name: spark-submit
    environment:
      SPARK_MASTER_NAME: analysis-spark-master
      SPARK_MASTER_PORT: 7077
      SPARK_APPLICATION_JAR_LOCATION: /spark/pattern-analysis-1.0-SNAPSHOT-all.jar
      SPARK_APPLICATION_MAIN_CLASS: io.github.rdsea.analysis.Main
      APP_CASSANDRA_HOST: cassandra
      APP_ELASTICSEARCH_HOST: elasticsearch
      APP_ELASTICSEARCH_PORT: 9200
      APP_FP_MIN_SUPPORT: 0.1
      APP_FP_MIN_CONFIDENCE: 0.5
    volumes:
      - $ETC_LOCALTIME:/etc/localtime:ro
      - ./reasoning/pattern-analysis/build/libs/pattern-analysis-1.0-SNAPSHOT-all.jar:/spark/pattern-analysis-1.0-SNAPSHOT-all.jar
    command: /bin/bash /submit.sh
    networks:
      - iot-big-data

  ##### OPTIONAL: WEB APPLICATION FOR LOOKING AT KAFKA BROKERS AND RECORDS #####
  ##### USE THIS IF YOU WANT TO DEBUG YOUR KAFKA TOPICS #####
  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: "no"
    ports:
      - 9000:9000
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
      JVM_OPTS: "-Xms32M -Xmx64M"
    networks:
      - iot-big-data
    depends_on:
      - kafka

networks:
  iot-big-data:
    driver: bridge
  pipeline:
    driver: bridge