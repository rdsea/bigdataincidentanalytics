version: '3.4'

services:

  ##### ELASTICSEARCH FOR STORING LOGS, METRICS #####
  elasticsearch:
    build:
      context: pipeline/elk/elasticsearch/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: elasticsearch
    volumes:
      - ./pipeline/elk/elasticsearch/data:/usr/share/elasticsearch/data
      - ./pipeline/elk/elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
      - $ETC_LOCALTIME:/etc/localtime:ro
    ports:
      - 9200:9200
      - 9300:9300
    environment:
      ES_JAVA_OPTS: "-Xmx256m -Xms256m"
    networks:
      - iot-big-data
      - pipeline

  ##### KIBANA FOR VISUALIZATION, DISCOVERY #####
  kibana:
    build:
      context: pipeline/elk/kibana/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: kibana
    volumes:
      - ./pipeline/elk/kibana/config/:/usr/share/kibana/config:ro
      - $ETC_LOCALTIME:/etc/localtime:ro
    ports:
      - 5601:5601
    networks:
      - iot-big-data
    depends_on:
      - elasticsearch

  ##### METRICBEAT FOR CENTRALIZING METRICS (PROMETHEUS, DOCKER, K8S) IN ELASTICSEARCH #####
  metricbeat:
    build:
      context: pipeline/elk/metricbeat/
      args:
        ELK_VERSION: $ELK_VERSION
    container_name: metricbeat
    user: root
    volumes:
      - ./pipeline/elk/metricbeat/config/metricbeat.docker.yml:/usr/share/metricbeat/metricbeat.yml:ro
      - /var/run/docker.sock:/var/run/docker.sock:ro
      - /sys/fs/cgroup:/hostfs/sys/fs/cgroup:ro
      - /proc:/hostfs/proc:ro
      - /:/hostfs:ro
      - $ETC_LOCALTIME:/etc/localtime:ro
    networks:
      - iot-big-data
    depends_on:
      - elasticsearch

  ##### FLUENTD FOR CENTRALIZING LOGS #####
  fluentd:
    build: logging/fluentd
    #image: fluentd:gcp_onpremise # use this image if you want to forward logs into Google Stackdriver
    container_name: fluentd
    volumes:
      #- ./logging/fluentd/gcp/onpremise:/fluentd/etc  # Mount this config for Stackdriver ingestion
      - ./logging/fluentd/conf:/fluentd/etc # Mount this config for local use
      - ./logging/fluentd/logs:/fluentd/log/bigdataincidentanalytics
      - ./logging/fluentd/logs/pipeline:/fluentd/log/bigdataincidentanalytics/pipeline
      # Mount the GCP credentials when ingesting to Stackdriver
      #- ./application_default_credentials.json:/etc/google/auth/application_default_credentials.json
      #- $ETC_LOCALTIME:/etc/localtime:ro
    #environment: # Set this environment variable when ingesting to Stackdriver
      #- APPLICATION_DEFAULT_CREDS="/etc/google/auth/application_default_credentials.json"
    networks:
      - iot-big-data
    ports:
      - 24224:24224
      - 24224:24224/udp
      - 9880:9880

  neo4j:
    #image: neo4j/neo4j-experimental:4.0.0-rc01
    image: neo4j:3.5.14
    container_name: neo4j
    environment:
      #- NEO4JLABS_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*,algo.*
      - NEO4J_AUTH=neo4j/test
    volumes:
      - ./reasoning/database/import:/var/lib/neo4j/import
      - ./reasoning/database/data:/data
      - ./reasoning/database/neo4j-graph-algorithms-3.5.14.0-standalone.jar:/var/lib/neo4j/plugins/neo4j-graph-algorithms-3.5.14.0-standalone.jar
      - ./reasoning/database/apoc-3.5.0.7-all.jar:/var/lib/neo4j/plugins/apoc-3.5.0.7-all.jar
    networks:
      - iot-big-data
    ports:
      - 7474:7474
      - 7687:7687

  zookeeper:
    image: wurstmeister/zookeeper
    container_name: zookeeper
    networks:
      - iot-big-data
      - pipeline
    ports:
      - 2181:2181

  kafka:
    image: wurstmeister/kafka:2.12-2.3.0
    container_name: kafka
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_CREATE_TOPICS: "signals:3:1"
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: INSIDE://:29092,OUTSIDE://192.168.0.95:9092
      KAFKA_LISTENERS: INSIDE://:29092,OUTSIDE://:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: INSIDE:PLAINTEXT,OUTSIDE:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: INSIDE
      KAFKA_OFFSETS_TOPIC_NUM_PARTITIONS: 3
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
    networks:
      - iot-big-data
      - pipeline
    ports:
      - 9092:9092

  kafdrop:
    image: obsidiandynamics/kafdrop
    container_name: kafdrop
    restart: "no"
    ports:
      - 9000:9000
    environment:
      KAFKA_BROKERCONNECT: "kafka:29092"
      JVM_OPTS: "-Xms32M -Xmx64M"
    networks:
      - iot-big-data
    depends_on:
      - kafka

  ingestion-service:
    image: ingestion-service:latest
    container_name: ingestion-service
    ports:
      - 3000:3000
    environment:
      KAFKA_BROKERS: "kafka:29092"  # separate multiple brokers by a comma e.g "kafka1:29092,kafka2:29092"
      KAFKA_TOPIC: signals
      NEO4J_URI: bolt://neo4j:7687
      NEO4J_USER: neo4j
      NEO4J_PASSWORD: test
    networks:
      - iot-big-data

networks:
  iot-big-data:
    driver: bridge
  pipeline:
    driver: bridge