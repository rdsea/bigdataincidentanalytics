# fluentd/conf/fluent.conf
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>
<source>
  @type http
  port 9880
  bind 0.0.0.0
  cors_allow_origins ["*"]
</source>

# Filter for concatenating multi-line stack-traces
<filter docker.**>
  @type concat
  key log
  stream_identity_key container_id
  multiline_start_regexp /^([0-9]{4}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1])( |T)(2[0-3]|[01][0-9]):[0-5][0-9]:[0-5][0-9])|([0-9]{2} [A-z]{3} (2[0-3]|[01][0-9]):[0-5][0-9]:[0-5][0-9])|([0-9]{2}\/(0[1-9]|1[0-2])\/(0[1-9]|[1-2][0-9]|3[0-1]) (2[0-3]|[01][0-9]):[0-5][0-9]:[0-5][0-9])/
  separator ""
  flush_interval 0
</filter>

<filter docker.mqtt>
  @type parser
  key_name log
  <parse>
    @type regexp
    expression /^(?<time>\d{10}):(?<log>.*?)$/
    time_format %s
  </parse>
</filter>

# ALL LOGS COMING WITH "docker.*" TAGS ARE CONSIDERED TO BE PLATFORM LOGS
<filter {docker.**,**.platform**}>
  @type record_modifier
  <record>
    software PLATFORM
  </record>
</filter>

# ALL LOGS WITH TAGS ENDING WITH "app" ARE CONSIDERED TO BE APPLICATION LOGS
<filter **.app.**>
  @type record_modifier
  <record>
    software APPLICATION
  </record>
</filter>

<filter **.platform**>
  @type record_modifier
  <record>
    log ${record['msg']}
  </record>
  remove_keys msg
</filter>

# FILTERS FOR SENSORS
<filter sensor.**.dataAsset>
  @type record_modifier
  <record>
    assetState IN_MOTION
    function DATA_EXTRACTION_INGESTION
  </record>
</filter>

# FILTERS FOR NODE-RED
<filter nodered.**.dataAsset>
  @type record_modifier
  <record>
    assetState AT_REST
    function DATA_STORAGE
  </record>
</filter>

# FILTERS FOR FLINK
<filter flink-processing.mqtt.*.dataAsset>
  @type record_modifier
  <record>
    assetState IN_PROCESSING
    function DATA_LOADING_PREPROCESSING
  </record>
</filter>
<filter flink-processing.aggregation.*.dataAsset>
  @type record_modifier
  <record>
    assetState IN_PROCESSING
    function DATA_PROCESSING
  </record>
</filter>
<filter flink-processing.storage.*.dataAsset>
  @type record_modifier
  <record>
    assetState IN_MOTION
    function DATA_EXTRACTION_INGESTION
  </record>
</filter>

# FILTERS FOR NIFI
<filter nifi.**.dataAsset>
  @type record_modifier
  <record>
    assetState IN_PROCESSING
    function DATA_LOADING_PREPROCESSING
  </record>
</filter>
<filter nifi.**.error>
  @type record_modifier
  <record>
    incident unavailable service
    function DATA_LOADING_PREPROCESSING
    effect REDUCTION_OF_QUALITY
  </record>
</filter>

# FILTERS FOR SPARK
<filter spark-kmeans.**.dataAsset>
  @type record_modifier
  <record>
    assetState IN_PROCESSING
    function DATA_ANALYSIS
  </record>
</filter>
<filter spark-kmeans.**.error>
  @type record_modifier
  <record>
    incident unavailable service
    function DATA_ANALYSIS
    effect UNPLANNED_INTERRUPTION
  </record>
</filter>

# Ingests every log into GCP Stackdriver
<match *.**>
  @type google_cloud
  use_metadata_service false
  @log_level info
  detect_json true
  project_id big-data-incident-analytics
  vm_id my-machine-name
  zone europe-west1-b
</match>
